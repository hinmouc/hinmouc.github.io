
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="与梦想等价交易，与善良并肩同行">
      
      
        <meta name="author" content="hinmouc">
      
      
      
      
      
      <link rel="icon" href="../../image/github.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4">
    
    
      
        <title>Evaluate for image fusion - hinmouc's desk</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../stylesheets/link.css">
    
      <link rel="stylesheet" href="../../stylesheets/customize.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#preamble" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="hinmouc&#39;s desk" class="md-header__button md-logo" aria-label="hinmouc's desk" data-md-component="logo">
      
  <img src="../../image/flower1.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            hinmouc's desk
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Evaluate for image fusion
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="teal"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="cyan"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    hinmouc.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Me

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../research/LaTeX.md" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  about

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="hinmouc&#39;s desk" class="md-nav__button md-logo" aria-label="hinmouc's desk" data-md-component="logo">
      
  <img src="../../image/flower1.png" alt="logo">

    </a>
    hinmouc's desk
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    hinmouc.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Me
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/LaTeX.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latex
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/Evaluate_IF.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Evaluate for image fusion
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    about
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#preamble" class="md-nav__link">
    <span class="md-ellipsis">
      Preamble
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1information-theory-based" class="md-nav__link">
    <span class="md-ellipsis">
      1.Information Theory-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.Information Theory-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-entropy-en" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Entropy (EN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Entropy (EN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-mutual-information-mi" class="md-nav__link">
    <span class="md-ellipsis">
      (2) Mutual Information (MI)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(2) Mutual Information (MI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_1" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_1" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-normalized-mutual-information-nmi" class="md-nav__link">
    <span class="md-ellipsis">
      (3) Normalized Mutual Information (NMI)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(3) Normalized Mutual Information (NMI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_2" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_2" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-feature-mutual-information-fmi" class="md-nav__link">
    <span class="md-ellipsis">
      (4) Feature Mutual Information (FMI)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(4) Feature Mutual Information (FMI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_3" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_3" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-quality-assessment-based-on-fusion-qabf" class="md-nav__link">
    <span class="md-ellipsis">
      (5) Quality Assessment Based on Fusion (Qabf)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(5) Quality Assessment Based on Fusion (Qabf)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_4" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_4" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-noise-based-fusion-performance-nabf" class="md-nav__link">
    <span class="md-ellipsis">
      (6) Noise-Based Fusion Performance (Nabf)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(6) Noise-Based Fusion Performance (Nabf)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_5" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_5" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7-nonlinear-correlated-information-entropy-q_ncie" class="md-nav__link">
    <span class="md-ellipsis">
      (7) Nonlinear Correlated Information Entropy (Q_ncie)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(7) Nonlinear Correlated Information Entropy (Q_ncie)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_6" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_6" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8-phase-congruency-evaluation-qp" class="md-nav__link">
    <span class="md-ellipsis">
      (8) Phase Congruency Evaluation (Qp)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(8) Phase Congruency Evaluation (Qp)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_7" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_7" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2image-feature-based" class="md-nav__link">
    <span class="md-ellipsis">
      2.Image Feature-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.Image Feature-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-standard-deviation-sd" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Standard Deviation (SD)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Standard Deviation (SD)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_8" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_8" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-spatial-frequency-sf" class="md-nav__link">
    <span class="md-ellipsis">
      (2) Spatial Frequency (SF)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(2) Spatial Frequency (SF)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_9" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_9" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-average-gradient-ag" class="md-nav__link">
    <span class="md-ellipsis">
      (3) Average Gradient (AG)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(3) Average Gradient (AG)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_10" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_10" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-edge-intensity-ei" class="md-nav__link">
    <span class="md-ellipsis">
      (4) Edge Intensity (EI)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(4) Edge Intensity (EI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_11" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_11" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4structural-similarity-based" class="md-nav__link">
    <span class="md-ellipsis">
      4.Structural Similarity-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.Structural Similarity-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-structural-similarity-index-measure-ssim" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Structural Similarity Index Measure (SSIM)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Structural Similarity Index Measure (SSIM)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_12" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_12" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-multiscale-structural-similarity-index-ms-ssim" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Multiscale Structural Similarity Index (MS-SSIM)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Multiscale Structural Similarity Index (MS-SSIM)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_13" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_13" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-feature-similarity-index-fsim" class="md-nav__link">
    <span class="md-ellipsis">
      (3) Feature Similarity Index (FSIM)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(3) Feature Similarity Index (FSIM)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_14" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_14" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4correlation-based" class="md-nav__link">
    <span class="md-ellipsis">
      4.Correlation-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.Correlation-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-correlation-coefficient-cc" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Correlation Coefficient (CC)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Correlation Coefficient (CC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_15" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_15" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-sum-of-the-correlations-of-differences-scd" class="md-nav__link">
    <span class="md-ellipsis">
      (2) Sum of the Correlations of Differences (SCD)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(2) Sum of the Correlations of Differences (SCD)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_16" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_16" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-nonlinear-correlation-coefficient-ncc" class="md-nav__link">
    <span class="md-ellipsis">
      (3) Nonlinear Correlation Coefficient (NCC)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(3) Nonlinear Correlation Coefficient (NCC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_17" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_17" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5human-perception-based" class="md-nav__link">
    <span class="md-ellipsis">
      5.Human Perception-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.Human Perception-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-the-visual-information-fidelity-for-fusion-viff" class="md-nav__link">
    <span class="md-ellipsis">
      (1) The visual information fidelity for fusion (VIFF)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) The visual information fidelity for fusion (VIFF)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_18" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_18" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-human-visual-perception-q_cb" class="md-nav__link">
    <span class="md-ellipsis">
      (2) Human Visual Perception (\(Q_{CB}\))
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(2) Human Visual Perception (\(Q_{CB}\))">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_19" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_19" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6error-based" class="md-nav__link">
    <span class="md-ellipsis">
      6.Error-Based
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.Error-Based">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-mean-square-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      (1) Mean Square Error (MSE)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(1) Mean Square Error (MSE)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_20" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_20" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-peak-signal-to-noise-ration-psnr" class="md-nav__link">
    <span class="md-ellipsis">
      (2) Peak signal to noise ration (PSNR)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="(2) Peak signal to noise ration (PSNR)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formulas_21" class="md-nav__link">
    <span class="md-ellipsis">
      Formulas：
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code_21" class="md-nav__link">
    <span class="md-ellipsis">
      Code：
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" class="md-nav__link">
    <span class="md-ellipsis">
      Reference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 style="text-align: center;">
  <span style="color: #589bd5; font-weight: bold;">Evaluate for image fusion</span>
</h1>

<hr />
<h2 id="preamble"><strong>Preamble</strong></h2>
<p>图像融合是将来自不同来源的图像信息合成一幅图像的过程，目的是提高图像的质量和有效性。在图像融合研究中，评估融合结果的质量至关重要。为此，许多图像融合质量评估指标应运而生，帮助我们量化融合图像的优劣。</p>
<p><span style="color: hsl(9, 100%, 60%);">以下是一些定量评估指标的定义以及代码，请随意使用以下整理内容。</span>
<span style="color: #589bd5;  font-weight: bold;">
<a href="https://hinmouc.github.io/">
More in @hinmouc
</a>
</span></p>
<hr />
<h2 id="overview">Overview</h2>
<table>
<thead>
<tr>
<th style="text-align: center;"><strong>Category</strong></th>
<th style="text-align: center;"><strong>Metric Name</strong></th>
<th style="text-align: center;"><strong>Chinese</strong></th>
<th style="text-align: center;"><strong>Description</strong></th>
<th style="text-align: center;"><strong>Direction</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>Information Theory-Based</strong></td>
<td style="text-align: center;"><strong>Entropy <span style="color: #589bd5;">(EN)</span></strong></td>
<td style="text-align: center;"><strong>信息熵</strong></td>
<td style="text-align: center;">衡量图像中包含的信息多少。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Mutual Information <span style="color: #589bd5;">(MI)</span></strong></td>
<td style="text-align: center;"><strong>互信息</strong></td>
<td style="text-align: center;">衡量两幅图像共享信息的多少。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Normalized Mutual Information <span style="color: #589bd5;">(NMI)</span></strong></td>
<td style="text-align: center;"><strong>归一化互信息</strong></td>
<td style="text-align: center;">互信息的标准化版本，消除尺度影响。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Feature Mutual Information <span style="color: #589bd5;">(FMI)</span></strong></td>
<td style="text-align: center;"><strong>特征互信息</strong></td>
<td style="text-align: center;">侧重于图像特征的互信息评估，帮助衡量图像中的特征信息共享。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Quality Assessment Based on Fusion <span style="color: #589bd5;">(Qabf)</span></strong></td>
<td style="text-align: center;"><strong>基于梯度的融合性能</strong></td>
<td style="text-align: center;">评估融合图像中梯度信息的保持，主要衡量图像清晰度与细节保持。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Noise-Based Fusion Performance <span style="color: #589bd5;">(Nabf)</span></strong></td>
<td style="text-align: center;"><strong>基于噪声评估的融合性能</strong></td>
<td style="text-align: center;">侧重于噪声对融合性能的影响，能够描述噪声抑制与保真度之间的平衡。</td>
<td style="text-align: center;"><span class="arithmatex">\(\downarrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Nonlinear Correlated Information Entropy <span style="color: #589bd5;">(Q_ncie)</span></strong></td>
<td style="text-align: center;"><strong>非线性相关信息熵</strong></td>
<td style="text-align: center;">结合非线性相关性与信息熵的混合评估方法，评估图像内容的复杂性。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Phase Consistency-Based Metric <span style="color: #589bd5;">(Qp)</span></strong></td>
<td style="text-align: center;"><strong>基于相位一致性的评价指标</strong></td>
<td style="text-align: center;">评估图像中各个部分的相位一致性，帮助描述图像细节的一致性。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Image Feature-Based</strong></td>
<td style="text-align: center;"><strong>Average Gradient <span style="color: #589bd5;">(AG)</span></strong></td>
<td style="text-align: center;"><strong>平均梯度</strong></td>
<td style="text-align: center;">衡量图像的清晰度和细节信息，通常用于评估图像的锐度和质量。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Standard Deviation <span style="color: #589bd5;">(SD)</span></strong></td>
<td style="text-align: center;"><strong>标准差</strong></td>
<td style="text-align: center;">描述图像像素值的分散程度，反映图像的纹理信息和复杂度。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Spatial Frequency <span style="color: #589bd5;">(SF)</span></strong></td>
<td style="text-align: center;"><strong>空间频率</strong></td>
<td style="text-align: center;">评估图像细节变化的频率，常用于评估图像的细节保留情况。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Edge Intensity <span style="color: #589bd5;">(EI)</span></strong></td>
<td style="text-align: center;"><strong>边缘强度</strong></td>
<td style="text-align: center;">用于评估图像的边缘信息，反映边缘清晰度和细节表现。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Structural Similarity-Based</strong></td>
<td style="text-align: center;"><strong>Structural Similarity Index <span style="color: #589bd5;">(SSIM)</span></strong></td>
<td style="text-align: center;"><strong>结构相似性指数</strong></td>
<td style="text-align: center;">评价图像的结构信息、对比度和亮度的相似性。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Multiscale SSIM <span style="color: #589bd5;">(MS-SSIM)</span></strong></td>
<td style="text-align: center;"><strong>多尺度结构相似性</strong></td>
<td style="text-align: center;">在多个尺度上评估图像的结构相似性。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Feature Similarity Index <span style="color: #589bd5;">(FSIM)</span></strong></td>
<td style="text-align: center;"><strong>特征相似性指数</strong></td>
<td style="text-align: center;">基于图像的特征进行结构相似性评估。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Correlation-Based</strong></td>
<td style="text-align: center;"><strong>Correlation Coefficient <span style="color: #589bd5;">(CC)</span></strong></td>
<td style="text-align: center;"><strong>相关系数</strong></td>
<td style="text-align: center;">评估图像之间的线性相关性，衡量它们之间的相关程度。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Sum of the Correlations of Differences <span style="color: #589bd5;">(SCD)</span></strong></td>
<td style="text-align: center;"><strong>差异相关和</strong></td>
<td style="text-align: center;">评估图像在频谱内容上的差异。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Nonlinear Correlation Coefficient <span style="color: #589bd5;">(NCC)</span></strong></td>
<td style="text-align: center;"><strong>非线性相关系数</strong></td>
<td style="text-align: center;">评估图像之间的非线性相关性，主要用于图像融合后的非线性相关度衡量。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Human Perception-Based</strong></td>
<td style="text-align: center;"><strong>Visual Information Fidelity <span style="color: #589bd5;">(VIF)</span></strong></td>
<td style="text-align: center;"><strong>视觉信息保真度</strong></td>
<td style="text-align: center;">从人类视觉系统角度评估图像质量，反映人眼感知的清晰度和信息保真度。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Human Visual Perception <span style="color: #589bd5;">(QCB)</span></strong></td>
<td style="text-align: center;"><strong>人类视觉感知</strong></td>
<td style="text-align: center;">考虑人类视觉特性的图像质量评估，侧重图像的感知质量。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><strong>Error-Based</strong></td>
<td style="text-align: center;"><strong>Mean Squared Error <span style="color: #589bd5;">(MSE)</span></strong></td>
<td style="text-align: center;"><strong>均方误差</strong></td>
<td style="text-align: center;">计算图像之间的平方差，评估误差大小。</td>
<td style="text-align: center;"><span class="arithmatex">\(\downarrow\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>Peak Signal-to-Noise Ratio <span style="color: #589bd5;">(PSNR)</span></strong></td>
<td style="text-align: center;"><strong>峰值信噪比</strong></td>
<td style="text-align: center;">基于MSE，评估图像质量的常用指标，信噪比越高，图像质量越好。</td>
<td style="text-align: center;"><span class="arithmatex">\(\uparrow\)</span></td>
</tr>
</tbody>
</table>
<hr />
<h1 style="text-align: center;">
  <span style="color: #eb7d2e; ">Detailed description</span>
</h1>

<p><span style="font-weight: bold;">Note: 下列代码所用到的check函数，如下所示</span></p>
<pre><code class="language-python">    @classmethod
    def input_check(cls, imgF, imgA=None, imgB=None): 
        if imgA is None:
            assert type(imgF) == np.ndarray, 'type error'
            assert len(imgF.shape) == 2, 'dimension error'
        else:
            assert type(imgF) == type(imgA) == type(imgB) == np.ndarray, 'type error'
            assert imgF.shape == imgA.shape == imgB.shape, 'shape error'
            assert len(imgF.shape) == 2, 'dimension error'
</code></pre>
<hr />
<h2 id="1information-theory-based">1.Information Theory-Based</h2>
<h3 id="1-entropy-en">(1) Entropy <span style="color: #589bd5; font-weight: bold;">(EN)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>信息熵</strong></li>
<li><strong>Calculation Object</strong>: <strong>Single Image</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a;  font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：信息熵用于量化图像的信息含量。在大多数应用中，较高的信息熵意味着图像包含更多的信息和细节。在图像融合中，高熵的融合结果表明图像综合了更多的源信息。</li>
</ul>
<hr />
<h4 id="formulas"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
H(i) = -\sum_{i=0}^{i-1} p(i) \log_2 p(i)
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(H(i)\)</span>：信息熵，衡量图像信息的不确定性或复杂性。</li>
<li><span class="arithmatex">\(p(i)\)</span>：像素值 <span class="arithmatex">\(i\)</span> 在图像中出现的概率，计算为像素值 <span class="arithmatex">\(i\)</span> 的频数除以图像中的总像素数。</li>
<li><span class="arithmatex">\(\log_2 p(i)\)</span>：以2为底的对数函数，用于计算以比特为单位的信息量。</li>
<li><span class="arithmatex">\(\sum_{i}\)</span>：求和符号，表示对所有可能的像素值 <span class="arithmatex">\(i\)</span> 进行累加。</li>
</ul>
<hr />
<h4 id="code"><strong>Code：</strong></h4>
<pre><code class="language-python">    @classmethod
    def EN(cls, img):  # entropy
        cls.input_check(img)
        a = np.uint8(np.round(img)).flatten()
        h = np.bincount(a) / a.shape[0]
        return -sum(h * np.log2(h + (h == 0)))
</code></pre>
<hr />
<h3 id="2-mutual-information-mi">(2) Mutual Information <span style="color: #589bd5;">(MI)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>互信息</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：互信息用于衡量两幅图像之间共享的信息量。互信息越大，表示两幅图像之间的重叠信息越多。例如，在图像融合中，较高的互信息值意味着融合图像综合了更多源图像的信息。</li>
</ul>
<hr />
<h4 id="formulas_1"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
MI = MI_{A,F} + MI_{B,F}
\]</div>
<p>其中<span class="arithmatex">\(MI_{X,F}\)</span>的表达式如下（X代表图像A或图像B）。融合图像的 MI 越高,意味着相应的融合算法从源图像中转移到融合图像中的信息越多，公式如下：</p>
<div class="arithmatex">\[
MI_{X,F} = \sum_{x,f} P_{X,F}(x,f) \log \frac{P_{X,F}(x,f)}{P_X(x) P_F(f)}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(MI_{X,F}\)</span>：两幅图像 <span class="arithmatex">\(X\)</span> 和 <span class="arithmatex">\(F\)</span> 之间的互信息。</li>
<li><span class="arithmatex">\(P_{X,F}(x,f)\)</span>：联合概率分布，表示图像 <span class="arithmatex">\(X\)</span> 中像素值为 <span class="arithmatex">\(x\)</span> 和图像 <span class="arithmatex">\(F\)</span> 中像素值为 <span class="arithmatex">\(f\)</span> 同时出现的概率。</li>
<li><span class="arithmatex">\(P_X(x)\)</span> 和 <span class="arithmatex">\(P_F(f)\)</span>：图像 <span class="arithmatex">\(X\)</span> 和 <span class="arithmatex">\(F\)</span> 的边缘概率分布。</li>
</ul>
<hr />
<h4 id="code_1"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def MI(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        return skm.mutual_info_score(image_F.flatten(), image_A.flatten()) +
            skm.mutual_info_score(image_F.flatten(), image_B.flatten())
</code></pre>
<hr />
<h3 id="3-normalized-mutual-information-nmi">(3) Normalized Mutual Information <span style="color: #589bd5;">(NMI)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>归一化互信息</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：归一化互信息（NMI）是互信息（MI）的标准化版本，用于度量两幅图像之间共享的信息量，相对于每幅图像自身的信息量。NMI的值范围通常在0到1之间，其中较高的NMI值意味着两幅图像之间的信息共享较多，特别适用于图像配准等任务。</li>
</ul>
<hr />
<h4 id="formulas_2"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\text{NMI}(X,Y) = \frac{2 \times \text{MI}(X,Y)}{H(X) + H(Y)}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(\text{NMI}(X, Y)\)</span>：归一化互信息，衡量两幅图像 <span class="arithmatex">\(X\)</span> 和 <span class="arithmatex">\(Y\)</span> 之间的标准化信息共享量。</li>
<li><span class="arithmatex">\(\text{MI}(X, Y)\)</span>：互信息，衡量两幅图像 <span class="arithmatex">\(X\)</span> 和 <span class="arithmatex">\(Y\)</span> 之间的共享信息量，公式见上文介绍。</li>
<li><span class="arithmatex">\(H(X)\)</span>：图像 <span class="arithmatex">\(X\)</span> 的信息熵，衡量图像 <span class="arithmatex">\(X\)</span> 的信息量。</li>
<li><span class="arithmatex">\(H(Y)\)</span>：图像 <span class="arithmatex">\(Y\)</span> 的信息熵，衡量图像 <span class="arithmatex">\(Y\)</span> 的信息量。</li>
<li><span class="arithmatex">\(\frac{2 \times \text{MI}(X,Y)}{H(X) + H(Y)}\)</span>：通过互信息与信息熵的比值来标准化信息共享量，避免尺度差异的影响。</li>
</ul>
<hr />
<h4 id="code_2"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_NMI(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)

        def calc_entropy(img):
            hist = np.histogram(img, bins=256)[0]
            hist = hist / hist.sum()
            hist = hist[hist &gt; 0]  # Remove zeros to avoid log(0)
            return -np.sum(hist * np.log2(hist))

        # Calculate entropy for each image
        H_F = calc_entropy(image_F)
        H_A = calc_entropy(image_A)
        H_B = calc_entropy(image_B)

        # Calculate mutual information between fused image and each source image
        MI_FA = mutual_info_score(None, None, contingency=np.histogram2d(image_F.ravel(), image_A.ravel(), bins=256)[0])
        MI_FB = mutual_info_score(None, None, contingency=np.histogram2d(image_F.ravel(), image_B.ravel(), bins=256)[0])

        # Calculate NMI for each pair
        NMI_FA = MI_FA / np.sqrt(H_F * H_A)
        NMI_FB = MI_FB / np.sqrt(H_F * H_B)

        # Return average NMI
        return (NMI_FA + NMI_FB) / 2
</code></pre>
<hr />
<h3 id="4-feature-mutual-information-fmi">(4) Feature Mutual Information <span style="color: #589bd5;">(FMI)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>特征互信息</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：特征互信息（FMI）是互信息的一种变体，专注于图像的频率域特征。它常用于评估图像融合的效果。FMI越高，表示更多的特征信息从源图像转移到融合图像中，尤其在图像融合与特征提取的任务中具有重要意义。</li>
</ul>
<hr />
<h4 id="formulas_3"><strong>Formulas</strong>：</h4>
<p><strong>First Formula</strong>:</p>
<div class="arithmatex">\[
FMI = MI_{A,F} + MI_{B,F}
\]</div>
<p><strong>Second Formula</strong>:</p>
<div class="arithmatex">\[
\text{FMI} = \sum \frac{|\text{FFT}(I_1) \cdot \text{conj}(\text{FFT}(I_2))|}{|\text{FFT}(I_1)| \cdot |\text{FFT}(I_2)|}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(MI_{A,F}\)</span>：源图像 <span class="arithmatex">\(A\)</span> 与融合图像 <span class="arithmatex">\(F\)</span> 之间的互信息。</li>
<li><span class="arithmatex">\(MI_{B,F}\)</span>：源图像 <span class="arithmatex">\(B\)</span> 与融合图像 <span class="arithmatex">\(F\)</span> 之间的互信息。</li>
<li><span class="arithmatex">\(\text{FFT}(I_1)\)</span>、<span class="arithmatex">\(\text{FFT}(I_2)\)</span>：对图像 <span class="arithmatex">\(I_1\)</span> 和 <span class="arithmatex">\(I_2\)</span> 进行快速傅里叶变换（FFT），将其从空间域转换到频率域。</li>
<li><span class="arithmatex">\(\text{conj}(\text{FFT}(I_2))\)</span>：对图像 <span class="arithmatex">\(I_2\)</span> 的FFT结果进行共轭操作。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和符号，表示对所有频率分量进行累加。</li>
</ul>
<hr />
<h4 id="code_3"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_FMI(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)

        def mutual_info(img1, img2):
            hist_2d, _, _ = np.histogram2d(img1.ravel(), img2.ravel(), bins=256)
            pxy = hist_2d / float(np.sum(hist_2d))
            px = np.sum(pxy, axis=1)  # marginal for x over y
            py = np.sum(pxy, axis=0)  # marginal for y over x
            px_py = px[:, None] * py[None, :]  # Broadcast to multiply marginals
            # Now we can do the calculation using the pxy, px_py 2D arrays
            nzs = pxy &gt; 0  # Only non-zero pxy values contribute to the sum
            return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))

        # Compute edges as features
        edges_F = feature.canny(image_F)
        edges_A = feature.canny(image_A)
        edges_B = feature.canny(image_B)

        FMI_A = mutual_info(edges_F, edges_A)
        FMI_B = mutual_info(edges_F, edges_B)

        # Here, we simply average the FMI values of two comparisons
        FMI = (FMI_A + FMI_B) / 2
        return FMI
</code></pre>
<hr />
<h3 id="5-quality-assessment-based-on-fusion-qabf">(5) Quality Assessment Based on Fusion <span style="color: #589bd5;">(Qabf)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>基于融合的质量评估</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：Qabf是一种新颖的融合图像客观非参考质量评估指标，旨在估计图像在融合后表现出的显著信息。该指标通过局部度量来估计每个输入图像信息在融合图像中的表现，值越高表示融合图像质量越好，通常用于图像融合任务中。</li>
</ul>
<hr />
<h4 id="formulas_4"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\mathrm{Q(a,b,f)~=~\frac{1}{|W|}\sum_{\omega\in W}\left(\lambda(\omega)Q_0\left(a,f|\omega\right)+\left(1-\lambda(\omega)\right)Q_0\left(b,f|\omega\right)\right)}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(Q_0(a,f|\omega)\)</span>：在局部窗口 <span class="arithmatex">\(\omega\)</span> 下，源图像 <span class="arithmatex">\(a\)</span> 与融合图像 <span class="arithmatex">\(f\)</span> 的质量评估。</li>
<li><span class="arithmatex">\(\lambda(\omega)\)</span>：与窗口 <span class="arithmatex">\(\omega\)</span> 相关的加权系数，反映图像局部信息的重要性。</li>
<li><span class="arithmatex">\(W\)</span>：图像的所有局部窗口集合，表示图像在空间上的分块。</li>
<li><span class="arithmatex">\(|W|\)</span>：窗口的总数，通常表示图像分块的数量。</li>
</ul>
<hr />
<h4 id="code_4"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def Qabf(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        gA, aA = cls.Qabf_getArray(image_A)
        gB, aB = cls.Qabf_getArray(image_B)
        gF, aF = cls.Qabf_getArray(image_F)
        QAF = cls.Qabf_getQabf(aA, gA, aF, gF)
        QBF = cls.Qabf_getQabf(aB, gB, aF, gF)

    # 计算QABF
     deno = np.sum(gA + gB)
     nume = np.sum(np.multiply(QAF, gA) + np.multiply(QBF, gB))
     return nume / deno

    @classmethod
    def Qabf_getArray(cls,img):

        # Sobel Operator Sobel

         h1 = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]).astype(np.float32)
         h2 = np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]]).astype(np.float32)
         h3 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).astype(np.float32)

         SAx = convolve2d(img, h3, mode='same')
         SAy = convolve2d(img, h1, mode='same')
         gA = np.sqrt(np.multiply(SAx, SAx) + np.multiply(SAy, SAy))
         aA = np.zeros_like(img)
         aA[SAx == 0] = math.pi / 2
         aA[SAx != 0]=np.arctan(SAy[SAx != 0] / SAx[SAx != 0])
         return gA, aA

    @classmethod
    def Qabf_getQabf(cls,aA, gA, aF, gF):
        L = 1
        Tg = 0.9994
        kg = -15
        Dg = 0.5
        Ta = 0.9879
        ka = -22
        Da = 0.8
        GAF,AAF,QgAF,QaAF,QAF = np.zeros_like(aA),np.zeros_like(aA),np.zeros_like(aA),np.zeros_like(aA),np.zeros_like(aA)
        GAF[gA&gt;gF]=gF[gA&gt;gF]/gA[gA&gt;gF]
        GAF[gA == gF] = gF[gA == gF]
        GAF[gA &lt;gF] = gA[gA&lt;gF]/gF[gA&lt;gF]
        AAF = 1 - np.abs(aA - aF) / (math.pi / 2)
        QgAF = Tg / (1 + np.exp(kg * (GAF - Dg)))
        QaAF = Ta / (1 + np.exp(ka * (AAF - Da)))
        QAF = QgAF* QaAF
        return QAF
</code></pre>
<hr />
<h3 id="6-noise-based-fusion-performance-nabf">(6) Noise-Based Fusion Performance <span style="color: #589bd5;">(Nabf)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>基于伪影的指标</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越小越好</span></li>
<li><strong>Description</strong>：基于伪影的指标（<span class="arithmatex">\(N^{AB/F}\)</span>）是一种评估图像融合质量的标准，它通过计算图像中伪影位置的影响，来衡量噪声对融合图像的影响。该指标的值越小，表示融合图像中噪声和伪影的影响越小，质量越高。</li>
</ul>
<hr />
<h4 id="formulas_5"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
N^{AB/F} = \frac{\sum_{i=1}^{M}\sum_{j=1}^{N}AM( i,j)\left[ ( 1 - Q^{A,F}( i,j) ) w^{A}( i,j) + ( 1 - Q^{B,F}( i,j) ) w^{B}( i,j) \right]}{\sum_{i=1}^{M} \sum_{j=1}^{N} ( w^{A}( i,j) + w^{n}( i,j) )}
\]</div>
<div class="arithmatex">\[
AM(i,j) =  
    \begin{cases}  
    1 &amp; \text{if } O^f_g(i,j) &gt; O^x_g(i,j) \\  
    0 &amp; \text{otherwise}  
    \end{cases}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(N^{AB/F}\)</span>：基于噪声的融合性能指标。</li>
<li><span class="arithmatex">\(AM(i,j)\)</span>：位置 (i,j) 在参考图像A和B的平均值。</li>
<li><span class="arithmatex">\(Q^{A,F}(i,j)\)</span> 和 <span class="arithmatex">\(Q^{B,F}(i,j)\)</span>：位置 (i,j) 在融合图像和参考图像A、B之间的质量评估指标。</li>
<li><span class="arithmatex">\(w^{A}(i,j)\)</span> 和 <span class="arithmatex">\(w^{B}(i,j)\)</span>：在位置 (i,j) 的权重因子，反映该位置的噪声敏感度。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和操作，用于累加整个图像区域。</li>
<li>AM(i,j)表示图像伪影位置，即如果融合图像中某处的边缘强度比源图像中相应位置处的都强,则判定为伪影</li>
</ul>
<hr />
<h4 id="code_5"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def estimate_noise(cls, I):
        H, W = I.shape
        M = [[1, -2, 1], [-2, 4, -2], [1, -2, 1]]
        sigma = np.sum(np.sum(np.abs(convolve2d(I, M, mode='same'))))
        return sigma / (H * W)

    @classmethod
    def Nabf(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        noise_F = cls.estimate_noise(image_F)
        noise_A = cls.estimate_noise(image_A)
        noise_B = cls.estimate_noise(image_B)

        if noise_A + noise_B == 0:
            return float('inf')  # 避免除以零
        Nabf = (noise_A + noise_B - 2 * noise_F) / (noise_A + noise_B)
        return Nabf
</code></pre>
<hr />
<h3 id="7-nonlinear-correlated-information-entropy-q_ncie">(7) Nonlinear Correlated Information Entropy <span style="color: #589bd5;">(Q_ncie)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>非线性相关信息熵</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：非线性相关信息熵 (Q_ncie) 用于评估图像间非线性关系的保持程度。它通过计算图像的联合概率分布来衡量图像之间非线性相关性的信息量。在医学成像等领域，该指标能够评估图像是否有效地保留了源图像中的非线性特征。</li>
</ul>
<hr />
<h4 id="formulas_6"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
Q_{ncie} = \sum_{x,f} \left( \frac{p(x,f)}{p(x)p(f)} \right) \log \left( \frac{p(x,f)}{p(x)p(f)} \right)
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(Q_{ncie}\)</span>：非线性相关信息熵。</li>
<li><span class="arithmatex">\(p(x,f)\)</span>：联合概率密度函数，表示两个图像像素值x和f同时出现的概率。</li>
<li><span class="arithmatex">\(p(x)\)</span> 和 <span class="arithmatex">\(p(f)\)</span>：两个图像的边缘概率密度函数。</li>
<li><span class="arithmatex">\(\log\)</span>：自然对数，用于计算信息熵。</li>
</ul>
<hr />
<h4 id="code_6"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_Q_ncie(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)

        # 计算图像间的非线性相关信息熵
        def calc_Q_ncie(img1, img2):
            joint_hist, _, _ = np.histogram2d(img1.ravel(), img2.ravel(), bins=256, density=True)
            pxy = joint_hist / np.sum(joint_hist)  # 联合概率
            px = np.sum(pxy, axis=1)  # 边缘概率
            py = np.sum(pxy, axis=0)
            pxy_nz = pxy[pxy &gt; 0]
            px_py = np.outer(px, py)[pxy &gt; 0]
            Q_ncie = np.sum(pxy_nz * np.log(pxy_nz / px_py))
            return Q_ncie

        # 计算融合图像与两个源图像的Q_ncie并取平均
        Q_ncie_FA = calc_Q_ncie(image_F, image_A)
        Q_ncie_FB = calc_Q_ncie(image_F, image_B)
        return (Q_ncie_FA + Q_ncie_FB) / 2
</code></pre>
<hr />
<h3 id="8-phase-congruency-evaluation-qp">(8) Phase Congruency Evaluation <span style="color: #589bd5;">(Qp)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>基于相位一致性的评价指标</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：基于相位一致性的评价指标 (Qp) 专注于评估图像中的相位一致性，反映了图像的边缘和特征的显著性和锐利度。相位一致性高的图像通常意味着图像的特征更加明显，对于边缘检测和图像融合等任务尤其重要。</li>
</ul>
<hr />
<h4 id="formulas_7"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
Q_p = \frac{1}{MN} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} PC_A(i,j) \cdot PC_F(i,j)
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(Q_p\)</span>：基于相位一致性的评价指标。</li>
<li><span class="arithmatex">\(PC_A(i,j)\)</span> 和 <span class="arithmatex">\(PC_F(i,j)\)</span>：分别是参考图像A和融合图像在位置(i, j)的相位一致性。</li>
<li><span class="arithmatex">\(M, N\)</span>：图像的宽度和高度。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和操作，用于累加所有像素点。</li>
</ul>
<hr />
<h4 id="code_7"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_Qp(cls, image_F, image_A, image_B):
        from skimage.feature import canny
        from skimage import img_as_float
        cls.input_check(image_F, image_A, image_B)

        # 使用Canny算子作为相位一致性的近似计算
        def calc_phase_congruency(img1, img2):
            pc1 = canny(img_as_float(img1))
            pc2 = canny(img_as_float(img2))
            return np.sum(pc1 == pc2) / np.sum(pc1 | pc2)  # 计算相位一致性指数

        # 计算融合图像与两个源图像的相位一致性指数并取平均
        Qp_FA = calc_phase_congruency(image_F, image_A)
        Qp_FB = calc_phase_congruency(image_F, image_B)
        return (Qp_FA + Qp_FB) / 2
</code></pre>
<hr />
<h2 id="2image-feature-based">2.Image Feature-Based</h2>
<h3 id="1-standard-deviation-sd">(1) Standard Deviation <span style="color: #589bd5;">(SD)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>标准差</strong></li>
<li><strong>Calculation Object</strong>: <strong>Single Image</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：标准差反映了图像像素值的变化范围，常用来评估图像的对比度、清晰度等。较高的标准差通常意味着图像具有较高的对比度和更清晰的细节，但过高的标准差可能导致噪声或失真。对于融合图像，SD越大，图像细节可能越丰富，但也需要平衡噪声和清晰度之间的关系。</li>
<li>
<p><strong>具体来说，SD的大小与融合图像的对比度、清晰度和一致性程度存在一定的关联，所以也并不是越大就一定越好。</strong></p>
</li>
<li>
<p>对比度： SD的大小与融合图像的对比度有一定的正相关关系，即SD越大，对比度可能也会越高。
       但是，过高的对比度可能导致图像过亮或过暗，影响观察体验。</p>
</li>
<li>
<p>清晰度： SD的大小与融合图像的清晰度也有一定的正相关关系，即SD越大，图像细节可能也会更加清晰。
     但是，过高的SD可能导致图像出现过多噪声或失真，影响观察体验。</p>
</li>
<li>
<p>一致性： SD的大小与融合图像的一致性程度没有明确的相关关系，因此SD的大小并不能直接反映融合图像的一致性。</p>
</li>
</ul>
<hr />
<h4 id="formulas_8"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
SD = \sqrt{\sum_{i=1}^M \sum_{j=1}^N (F(i,j) - \mu)^2}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(SD\)</span>：标准差，衡量像素值相对于平均值的变异程度。</li>
<li><span class="arithmatex">\(F(i,j)\)</span>：图像在位置 <span class="arithmatex">\((i, j)\)</span> 的像素值。</li>
<li><span class="arithmatex">\(\mu\)</span>：图像的平均像素值。</li>
<li><span class="arithmatex">\(\sum_{i=1}^M \sum_{j=1}^N\)</span>：求和符号，表示对所有像素值进行累加。</li>
</ul>
<hr />
<h4 id="code_8"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def SD(cls, img):
        cls.input_check(img)
        return np.std(img)
</code></pre>
<hr />
<h3 id="2-spatial-frequency-sf">(2) Spatial Frequency <span style="color: #589bd5;">(SF)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>空间频率</strong></li>
<li><strong>Calculation Object</strong>: <strong>Single Image</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：空间频率反映了图像灰度值变化的速度，通常用于衡量图像的清晰度。较高的空间频率意味着图像具有更多的边缘和细节，融合图像的质量通常越高。
SF通过计算图像的梯度变化来揭示图像的纹理和边缘信息，是图像清晰度和细节的有效指标。</li>
</ul>
<hr />
<h4 id="formulas_9"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\mathrm{SF}\:=\:\sqrt{\mathrm{RF}^2+\mathrm{CF}^2}
\]</div>
<p>其中，</p>
<div class="arithmatex">\[
\mathrm{RF~=~\sqrt{\frac{1}{MN}\sum_{i=1}^M\sum_{j=1}^N\left(H(i,j)-H(i,j-1)\right
)^2}}
\]</div>
<div class="arithmatex">\[
\mathrm{CF~=~\sqrt{\frac{1}{MN}\sum_{i=1}^M\sum_{j=1}^N\left(H(i,j)-H(i-1,j)\right)^2}}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(RF\)</span>：表示行频率。</li>
<li><span class="arithmatex">\(CF\)</span>：表示列频率。</li>
</ul>
<hr />
<h4 id="code_9"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def SF(cls, img):
        cls.input_check(img)
        return np.sqrt(np.mean((img[:, 1:] - img[:, :-1]) ** 2) + np.mean((img[1:, :] - img[:-1, :]) ** 2))
</code></pre>
<hr />
<h3 id="3-average-gradient-ag">(3) Average Gradient <span style="color: #589bd5;">(AG)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>平均梯度</strong></li>
<li><strong>Calculation Object</strong>: <strong>Single Image</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：平均梯度用于衡量图像的清晰度，它是通过计算图像中相邻像素之间的梯度来评估图像的锐利程度。在图像融合中，较高的平均梯度值通常意味着图像包含更多细节，并且融合质量较高。</li>
</ul>
<hr />
<h4 id="formulas_10"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\mathrm{AG~=~\frac{1}{(M-1)(N-1)}\sum_{i=1}^{M-1}\sum_{i=1}^{N-1}\sqrt{\frac{\left(H(i+1,j)-H(i,j)\right)^2+\left(H(i,j+1)-H(i,j)\right)^2}{2}}}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(AG\)</span>：平均梯度，衡量图像中像素变化的平均程度，反映了图像的清晰度。</li>
<li><span class="arithmatex">\(H(i,j)\)</span>：融合图像在位置 <span class="arithmatex">\((i,j)\)</span> 的像素值。</li>
<li><span class="arithmatex">\(M\)</span> 和 <span class="arithmatex">\(N\)</span>：图像的高度和宽度，分别表示图像的行数和列数。</li>
<li><span class="arithmatex">\(Gx\)</span> 和 <span class="arithmatex">\(Gy\)</span>：图像在水平方向和垂直方向的梯度。</li>
</ul>
<hr />
<h4 id="code_10"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def AG(cls, img):  # Average gradient
        cls.input_check(img)
        Gx, Gy = np.zeros_like(img), np.zeros_like(img)
        Gx[:, 0] = img[:, 1] - img[:, 0]
        Gx[:, -1] = img[:, -1] - img[:, -2]
        Gx[:, 1:-1] = (img[:, 2:] - img[:, :-2]) / 2

        Gy[0, :] = img[1, :] - img[0, :]
        Gy[-1, :] = img[-1, :] - img[-2, :]
        Gy[1:-1, :] = (img[2:, :] - img[:-2, :]) / 2
        return np.mean(np.sqrt((Gx ** 2 + Gy ** 2) / 2))
</code></pre>
<hr />
<h3 id="4-edge-intensity-ei">(4) Edge Intensity <span style="color: #589bd5;">(EI)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>边缘强度</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越小越好</span></li>
<li><strong>Description</strong>：边缘强度（EI）是用来评估图像中边缘的清晰度和强度的一个指标。边缘通常代表了图像中显著的结构信息，对于图像融合来说，保留原始图像中的边缘信息是确保融合质量的重要因素。</li>
</ul>
<hr />
<h4 id="formulas_11"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
EI = \frac{1}{MN} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} |E_F(i,j) - E_A(i,j)|
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(EI\)</span>：边缘强度指标。</li>
<li><span class="arithmatex">\(E_F(i,j)\)</span>：融合图像在位置 (i,j) 的边缘强度。</li>
<li><span class="arithmatex">\(E_A(i,j)\)</span>：参考图像A在位置 (i,j) 的边缘强度。</li>
<li><span class="arithmatex">\(M, N\)</span>：图像的宽度和高度。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和操作，用于累加所有像素点。</li>
</ul>
<hr />
<h4 id="code_11"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_avg_EI(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        ei_A = np.mean(np.abs(filters.sobel(image_F) - filters.sobel(image_A)))
        ei_B = np.mean(np.abs(filters.sobel(image_F) - filters.sobel(image_B)))
        avg_EI = (ei_A + ei_B) / 2
        return avg_EI
</code></pre>
<hr />
<h2 id="4structural-similarity-based">4.Structural Similarity-Based</h2>
<h3 id="1-structural-similarity-index-measure-ssim">(1) Structural Similarity Index Measure <span style="color: #589bd5;">(SSIM)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>结构相似性</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：SSIM（结构相似性指数）用于衡量两幅图像的相似度，考虑了亮度、对比度和结构三个方面的信息。SSIM 值的范围为[-1, 1]，值越接近 1 表示两幅图像越相似，越接近 -1 表示图像越不相似，值为 0 表示图像完全不同。它主要用于评估图像融合结果的质量。</li>
</ul>
<hr />
<h4 id="formulas_12"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\text{SSIM} = \frac{SSIM_{A,F}+SSIM_{B,F}}2
\]</div>
<p>其中,</p>
<div class="arithmatex">\[
SSIM_{X,F} = \sum_{x,f} \left(\frac{2 \mu_x \mu_f + C_1}{\mu_x^2 + \mu_f^2 + C_1} \times \frac{2 \sigma_{xf} + C_2}{\sigma_x^2 + \sigma_f^2 + C_2} \times \frac{\sigma_{xf} + C_3}{\sigma_x \sigma_f + C_3}\right)
\]</div>
<p><strong>element:</strong></p>
<ul>
<li><span class="arithmatex">\(\mu_x, \mu_f\)</span>：图像 X 和 F 的局部均值。</li>
<li><span class="arithmatex">\(\sigma_x, \sigma_f\)</span>：图像 X 和 F 的局部标准差。</li>
<li><span class="arithmatex">\(\sigma_{xf}\)</span>：X 和 F 的局部协方差。</li>
<li><span class="arithmatex">\(C_1, C_2, C_3\)</span>：为了避免分母为零而添加的小常数。代码如下：（越接近1越好，输入三幅图像）</li>
</ul>
<hr />
<h4 id="code_12"><strong>Code</strong>：</h4>
<pre><code class="language-python">   from skimage.metrics import structural_similarity as ssim
    @classmethod
    def SSIM(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        return ssim(image_F,image_A)+ssim(image_F,image_B)
</code></pre>
<hr />
<h3 id="1-multiscale-structural-similarity-index-ms-ssim">(1) Multiscale Structural Similarity Index <span style="color: #589bd5;">(MS-SSIM)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>多尺度结构相似性</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：多尺度结构相似性指数（MS-SSIM）是对传统SSIM的一种扩展，通过在多个尺度上评估图像的结构相似性，提供了更为精确的质量评估方法。它模拟了人眼对图像质量的感知，采用多级下采样，在每个尺度上计算SSIM值，并通过加权方式结合这些信息，以反映图像质量的多尺度感知。</li>
</ul>
<hr />
<h4 id="formulas_13"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
MS\text{-}SSIM(x, f) = [L_M(x, f)]^{\alpha_M} \times \prod_{j=1}^{M} [c_j(x, f)]^{\beta_j} \times [s_j(x, f)]^{\gamma_j}
\]</div>
<p><strong>element</strong>:</p>
<ul>
<li><span class="arithmatex">\(L_M(x, f)\)</span>：在 M 尺度上的亮度比较。</li>
<li><span class="arithmatex">\(c_j(x, f)\)</span>：在第 j 尺度上的对比度比较。</li>
<li><span class="arithmatex">\(s_j(x, f)\)</span>：在第 j 尺度上的结构比较。</li>
<li><span class="arithmatex">\(\alpha_M, \beta_j, \gamma_j\)</span>：是加权指数，用于调整不同尺度、亮度、对比度和结构比较的重要性。</li>
</ul>
<hr />
<h4 id="code_13"><strong>Code</strong>：</h4>
<p>MS-SSIM的计算一般较为复杂，需要在多个尺度上进行图像处理。由于 <code>skimage</code> 的 <code>ssim</code> 计算方法并不支持多尺度直接计算，我们通常需要使用外部库或者自己实现多尺度的过程。以下是一个大致的实现框架：</p>
<pre><code class="language-python">    from skimage.metrics import structural_similarity as ssim
    import numpy as np

    def calculate_ms_ssim(image_F, image_A, image_B, max_scale=5):
        def downsample_image(image):
            # 用于图像下采样的简单函数，可以使用不同的方法
            return image[::2, ::2]  # 这里用的是2x下采样，实际可以用更多下采样方法

        def compute_single_scale_ssim(image1, image2):
            return ssim(image1, image2)

        ms_ssim_A, ms_ssim_B = 1.0, 1.0
        for scale in range(max_scale):
            image_A_downsampled = downsample_image(image_A)
            image_F_downsampled = downsample_image(image_F)
            image_B_downsampled = downsample_image(image_B)

            # 计算每个尺度上的SSIM
            scale_ssim_A = compute_single_scale_ssim(image_A_downsampled, image_F_downsampled)
            scale_ssim_B = compute_single_scale_ssim(image_B_downsampled, image_F_downsampled)

            # 结合每个尺度的结果
            ms_ssim_A *= scale_ssim_A
            ms_ssim_B *= scale_ssim_B

            # 下采样后的图像继续作为下一尺度的输入
            image_A = image_A_downsampled
            image_F = image_F_downsampled
            image_B = image_B_downsampled

        # 最终MS-SSIM为所有尺度结果的乘积
        ms_ssim = (ms_ssim_A + ms_ssim_B) / 2
        return ms_ssim
</code></pre>
<hr />
<h3 id="3-feature-similarity-index-fsim">(3) Feature Similarity Index <span style="color: #589bd5;">(FSIM)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>特征相似性指数</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：特征相似性指数（FSIM）是一种通过对比图像的局部特征来衡量图像融合效果的质量评估指标。该指标特别关注图像的结构特征，通过计算图像在各个位置的均值、标准差及它们的关系来量化融合图像与参考图像的相似度。</li>
</ul>
<hr />
<h4 id="formulas_14"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
FSIM = \frac{1}{MN} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} \left( \frac{2 \mu_A(i,j) \mu_F(i,j) + C_1}{\mu_A^2(i,j) + \mu_F^2(i,j) + C_1} \right) \times \left( \frac{2 \sigma_{AF}(i,j) + C_2}{\sigma_A(i,j) + \sigma_F(i,j) + C_2} \right)
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(FSIM\)</span>：特征相似性指数。</li>
<li><span class="arithmatex">\(\mu_A(i,j)\)</span> 和 <span class="arithmatex">\(\mu_F(i,j)\)</span>：在位置 (i,j) 的参考图像A和融合图像的局部均值。</li>
<li><span class="arithmatex">\(\sigma_A(i,j)\)</span> 和 <span class="arithmatex">\(\sigma_F(i,j)\)</span>：在位置 (i,j) 的参考图像A和融合图像的局部标准差。</li>
<li><span class="arithmatex">\(C_1, C_2\)</span>：为了避免除零错误而添加的小常数。</li>
<li><span class="arithmatex">\(M, N\)</span>：图像的宽度和高度。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和操作，用于累加所有像素点。</li>
</ul>
<p><strong>算法描述</strong>： FSIM通过计算图像的局部均值和标准差来评估图像的特征相似性。对于每个像素点，FSIM考虑了该点周围的均值和标准差，以反映图像的结构特征。然后，这些特征信息在图像的所有像素点上进行累加，从而得到融合图像与参考图像之间的整体相似性。FSIM特别关注结构信息，因此对图像的细节保留非常敏感。</p>
<hr />
<h4 id="code_14"><strong>Code</strong>：</h4>
<pre><code class="language-python">import numpy as np

class ImageMetrics:
    @classmethod
    def FSIM(cls, image_F, image_A, image_B):
        &quot;&quot;&quot;
        计算特征相似性指数 (FSIM)。
        :param image_F: 融合图像
        :param image_A: 参考图像 A
        :param image_B: 参考图像 B
        :return: FSIM 值
        &quot;&quot;&quot;
        cls.input_check(image_F, image_A, image_B)

        def compute_fsim(img1, img2):
            &quot;&quot;&quot;
            计算图像之间的 FSIM 值。
            :param img1: 融合图像
            :param img2: 参考图像
            :return: FSIM 值
            &quot;&quot;&quot;
            # 计算局部均值和标准差
            mu_img1 = cv2.GaussianBlur(img1, (3, 3), 0)
            mu_img2 = cv2.GaussianBlur(img2, (3, 3), 0)
            sigma_img1 = cv2.GaussianBlur(img1 ** 2, (3, 3), 0) - mu_img1 ** 2
            sigma_img2 = cv2.GaussianBlur(img2 ** 2, (3, 3), 0) - mu_img2 ** 2
            sigma_img1 = np.sqrt(sigma_img1)
            sigma_img2 = np.sqrt(sigma_img2)

            # 计算特征相似性
            numerator = 2 * mu_img1 * mu_img2 + 1e-6
            denominator = mu_img1 ** 2 + mu_img2 ** 2 + 1e-6
            similarity = numerator / denominator

            numerator_sigma = 2 * sigma_img1 * sigma_img2 + 1e-6
            denominator_sigma = sigma_img1 ** 2 + sigma_img2 ** 2 + 1e-6
            similarity_sigma = numerator_sigma / denominator_sigma

            fsim_map = similarity * similarity_sigma
            return np.mean(fsim_map)

        # 计算两个参考图像与融合图像的 FSIM
        fsim_A = compute_fsim(image_F, image_A)
        fsim_B = compute_fsim(image_F, image_B)

        # 取平均值
        return (fsim_A + fsim_B) / 2
</code></pre>
<hr />
<h2 id="4correlation-based">4.Correlation-Based</h2>
<h3 id="1-correlation-coefficient-cc">(1) Correlation Coefficient <span style="color: #589bd5;">(CC)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>相关系数</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：相关系数（CC）用于衡量两幅图像之间的线性相关性。它常用于评估图像的相似性，特别是在图像融合中，用于评估融合图像与源图像之间的相似度。相关系数越高，表示融合图像与源图像越相似。</li>
</ul>
<hr />
<h4 id="formulas_15"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
CC = \frac{r(A,F) + r(B,F)}{2}
\]</div>
<div class="arithmatex">\[
r(X,F) = \frac{\sum_{i=1}^M \sum_{j=1}^N (X(i,j) - \bar{X})(F(i,j) - \mu)}{\sqrt{\sum_{i=1}^M \sum_{j=1}^N (X(i,j) - \bar{X})^2 \sum_{i=1}^M \sum_{j=1}^N (F(i,j) - \mu)^2}}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(r(A,F)\)</span> 和 <span class="arithmatex">\(r(B,F)\)</span>：分别表示源图像 <span class="arithmatex">\(A\)</span>、<span class="arithmatex">\(B\)</span> 与融合图像 <span class="arithmatex">\(F\)</span> 之间的相关系数。</li>
<li><span class="arithmatex">\(\bar{X}\)</span> 和 <span class="arithmatex">\(\bar{F}\)</span>：分别是图像 <span class="arithmatex">\(X\)</span> 和融合图像 <span class="arithmatex">\(F\)</span> 的平均像素值。</li>
<li><span class="arithmatex">\(X(i,j)\)</span> 和 <span class="arithmatex">\(F(i,j)\)</span>：位置 <span class="arithmatex">\((i,j)\)</span> 的像素值。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和符号，表示对所有像素位置的贡献进行累加。</li>
<li>根号内的乘积：用于归一化相关性计算，保证结果在 -1 到 1 之间。</li>
</ul>
<hr />
<h4 id="code_15"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def CC(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        rAF = np.sum((image_A - np.mean(image_A)) * (image_F - np.mean(image_F))) / np.sqrt(
            (np.sum((image_A - np.mean(image_A)) ** 2)) * (np.sum((image_F - np.mean(image_F)) ** 2)))
        rBF = np.sum((image_B - np.mean(image_B)) * (image_F - np.mean(image_F))) / np.sqrt(
            (np.sum((image_B - np.mean(image_B)) ** 2)) * (np.sum((image_F - np.mean(image_F)) ** 2)))
        return (rAF + rBF) / 2
</code></pre>
<h3 id="2-sum-of-the-correlations-of-differences-scd">(2) Sum of the Correlations of Differences <span style="color: #589bd5;">(SCD)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>差异相关和</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越高越好</span></li>
<li><strong>Description</strong>：差异相关和 (SCD) 用于衡量融合图像与源图像之间的差异，具体通过计算源图像与融合图像的差异图像之间的相关性来进行评估。SCD 值越高，表示融合图像保留了更多源图像的信息，质量越好。</li>
</ul>
<hr />
<h4 id="formulas_16"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
SCD = r(A,D_{A,F}) + r(B,D_{B,F})
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(r(A, D_{A,F})\)</span> 和 <span class="arithmatex">\(r(B, D_{B,F})\)</span>：分别表示源图像 <span class="arithmatex">\(A\)</span>、<span class="arithmatex">\(B\)</span> 与它们与融合图像 <span class="arithmatex">\(F\)</span> 的差异图像 <span class="arithmatex">\(D_{A,F}\)</span>、<span class="arithmatex">\(D_{B,F}\)</span> 之间的相关系数。</li>
<li><span class="arithmatex">\(D_{A,F}\)</span>：表示源图像 <span class="arithmatex">\(A\)</span> 和融合图像 <span class="arithmatex">\(F\)</span> 之间的差异图像，即 <span class="arithmatex">\(D_{A,F} = F - A\)</span>。</li>
<li><span class="arithmatex">\(D_{B,F}\)</span>：表示源图像 <span class="arithmatex">\(B\)</span> 和融合图像 <span class="arithmatex">\(F\)</span> 之间的差异图像，即 <span class="arithmatex">\(D_{B,F} = F - B\)</span>。</li>
</ul>
<h4 id="code_16"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def SCD(cls, image_F, image_A, image_B): # The sum of the correlations of differences
        cls.input_check(image_F, image_A, image_B)
        # 计算差异图像
        imgF_A = image_F - image_A
        imgF_B = image_F - image_B
        corr1 = np.sum((image_A - np.mean(image_A)) * (imgF_B - np.mean(imgF_B))) / np.sqrt(
            (np.sum((image_A - np.mean(image_A)) ** 2)) * (np.sum((imgF_B - np.mean(imgF_B)) ** 2)))
        corr2 = np.sum((image_B - np.mean(image_B)) * (imgF_A - np.mean(imgF_A))) / np.sqrt(
            (np.sum((image_B - np.mean(image_B)) ** 2)) * (np.sum((imgF_A - np.mean(imgF_A)) ** 2)))
        return corr1 + corr2
</code></pre>
<hr />
<h3 id="3-nonlinear-correlation-coefficient-ncc">(3) Nonlinear Correlation Coefficient <span style="color: #589bd5;">(NCC)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>非线性相关系数</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越高越好</span></li>
<li><strong>Description</strong>：非线性相关系数（NCC）用于衡量融合图像与源图像之间的非线性关系。该指标用于评估融合图像能否有效地保持源图像中非线性特征的相关性。NCC 越高，表示融合图像与源图像的非线性相关程度越高，融合效果越好。</li>
</ul>
<hr />
<h4 id="formulas_17"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
NCC = \frac{NCC_{AF} + NCC_{bF}}{2}
\]</div>
<div class="arithmatex">\[
NCC_{XF} = 2 + \sum_{i} S_i \log \frac{S_i}{S_b} S'_i
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(S_i\)</span>：第 <span class="arithmatex">\(i\)</span> 个秩中样本分布的数量。</li>
<li><span class="arithmatex">\(S_b\)</span>：秩的总数。</li>
<li><span class="arithmatex">\(S\)</span>：样本对的总数。</li>
<li><span class="arithmatex">\(S'_i\)</span>：样本的变动量。</li>
</ul>
<h4 id="code_17"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def calculate_NCC(cls, image_F, image_A, image_B):
        '''
        非线性相关系数 (NCC)
        '''
        cls.input_check(image_F, image_A, image_B)

        def calc_NCC(img1, img2):
            # 标准化图像
            img1_mean_sub = img1 - np.mean(img1)
            img2_mean_sub = img2 - np.mean(img2)
            norm1 = np.linalg.norm(img1_mean_sub)
            norm2 = np.linalg.norm(img2_mean_sub)
            ncc = np.sum(img1_mean_sub * img2_mean_sub) / (norm1 * norm2)
            return ncc

        # 计算融合图像与两个源图像的NCC并取平均
        NCC_FA = calc_NCC(image_F, image_A)
        NCC_FB = calc_NCC(image_F, image_B)
        return (NCC_FA + NCC_FB) / 2
</code></pre>
<hr />
<h2 id="5human-perception-based">5.Human Perception-Based</h2>
<h3 id="1-the-visual-information-fidelity-for-fusion-viff">(1)  The visual information fidelity for fusion <span style="color: #589bd5;">(VIFF)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>视觉信息保真度</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：视觉信息保真度（VIFF）是一种基于视觉信息保真度的图像质量评估指标，广泛应用于图像融合质量的评估。VIFF 通过衡量图像在不同频带下的条件信息量来评价图像的融合效果。值越大表示融合图像的质量越高，能够保留更多的源图像信息。</li>
</ul>
<hr />
<h4 id="formulas_18"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
VIF_{X,F} = \frac{\sum_{i \in \text{subbands}} I(C^{S,i}, F^{S,i} \mid R^{S,i})}{\sum_{i \in \text{subbands}} I(C^{S,i}, X^{S,i} \mid R^{S,i})}
\]</div>
<p><strong>elemen</strong>：</p>
<ul>
<li><span class="arithmatex">\(I(C^{S,i}, F^{S,i} \mid R^S_i)\)</span> 和 <span class="arithmatex">\(I(C^{S,i}, X^{S,i} \mid R^S_i)\)</span>：分别表示条件信息量，表示在给定参考信号 <span class="arithmatex">\(R^S_i\)</span> 的情况下，通道 <span class="arithmatex">\(C\)</span> 中融合图像 <span class="arithmatex">\(F\)</span> 和源图像 <span class="arithmatex">\(X\)</span> 的信息量。</li>
<li><span class="arithmatex">\(\text{subbands}\)</span>：图像被分割的频带，表示不同频率范围内的信息。</li>
<li><span class="arithmatex">\(C^{S,i}\)</span>、<span class="arithmatex">\(F^{S,i}\)</span> 和 <span class="arithmatex">\(X^{S,i}\)</span>：分别表示在第 i 个频带上的图像特征。</li>
</ul>
<hr />
<h4 id="code_18"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def VIFF(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        return cls.compare_viff(image_A, image_F)+cls.compare_viff(image_B, image_F)

    @classmethod
    def compare_viff(cls,ref, dist): # viff of a pair of pictures
        sigma_nsq = 2
        eps = 1e-10

        num = 0.0
        den = 0.0
        for scale in range(1, 5):

            N = 2 ** (4 - scale + 1) + 1
            sd = N / 5.0

            # Create a Gaussian kernel as MATLAB's
            m, n = [(ss - 1.) / 2. for ss in (N, N)]
            y, x = np.ogrid[-m:m + 1, -n:n + 1]
            h = np.exp(-(x * x + y * y) / (2. * sd * sd))
            h[h &lt; np.finfo(h.dtype).eps * h.max()] = 0
            sumh = h.sum()
            if sumh != 0:
                win = h / sumh

            if scale &gt; 1:
                ref = convolve2d(ref, np.rot90(win, 2), mode='valid')
                dist = convolve2d(dist, np.rot90(win, 2), mode='valid')
                ref = ref[::2, ::2]
                dist = dist[::2, ::2]

            mu1 = convolve2d(ref, np.rot90(win, 2), mode='valid')
            mu2 = convolve2d(dist, np.rot90(win, 2), mode='valid')
            mu1_sq = mu1 * mu1
            mu2_sq = mu2 * mu2
            mu1_mu2 = mu1 * mu2
            sigma1_sq = convolve2d(ref * ref, np.rot90(win, 2), mode='valid') - mu1_sq
            sigma2_sq = convolve2d(dist * dist, np.rot90(win, 2), mode='valid') - mu2_sq
            sigma12 = convolve2d(ref * dist, np.rot90(win, 2), mode='valid') - mu1_mu2

            sigma1_sq[sigma1_sq &lt; 0] = 0
            sigma2_sq[sigma2_sq &lt; 0] = 0

            g = sigma12 / (sigma1_sq + eps)
            sv_sq = sigma2_sq - g * sigma12

            g[sigma1_sq &lt; eps] = 0
            sv_sq[sigma1_sq &lt; eps] = sigma2_sq[sigma1_sq &lt; eps]
            sigma1_sq[sigma1_sq &lt; eps] = 0

            g[sigma2_sq &lt; eps] = 0
            sv_sq[sigma2_sq &lt; eps] = 0

            sv_sq[g &lt; 0] = sigma2_sq[g &lt; 0]
            g[g &lt; 0] = 0
            sv_sq[sv_sq &lt;= eps] = eps

            num += np.sum(np.log10(1 + g * g * sigma1_sq / (sv_sq + sigma_nsq)))
            den += np.sum(np.log10(1 + sigma1_sq / sigma_nsq))

        vifp = num / den

        if np.isnan(vifp):
            return 1.0
        else:
            return vifp
</code></pre>
<hr />
<h3 id="2-human-visual-perception-q_cb">(2) Human Visual Perception <span style="color: #589bd5;">(<span class="arithmatex">\(Q_{CB}\)</span>)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>人类视觉感知</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越接近1越好</span></li>
<li><strong>Description</strong>：<strong><span class="arithmatex">\(Q_{CB}\)</span></strong> 是一个基于人类视觉系统的指标，用于衡量融合图像与源图像之间主要特征的相似度。该指标从人类视觉感知的角度出发，越大的Q_CB值表示融合图像能更好地保留源图像中的关键信息。Q_CB值越大，说明融合图像越接近源图像的视觉感知效果，融合效果越好。</li>
</ul>
<hr />
<h4 id="formulas_19"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
Q_{CB} = \frac{1}{MN} \left( \sum_{i=1}^{N} \sum_{j=1}^{N} \beta_{A}(i,j) W_{A,F}(i,j) + \beta_B(i,j) W_{B,F}(i,j) \right)
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(Q_{CB}\)</span>：表示人类视觉感知的质量评估值。</li>
<li><span class="arithmatex">\(\beta_{A}(i,j)\)</span> 和 <span class="arithmatex">\(\beta_B(i,j)\)</span>：显著图，表示源图像 <span class="arithmatex">\(A\)</span> 和 <span class="arithmatex">\(B\)</span> 在位置 <span class="arithmatex">\((i,j)\)</span> 处的显著性。显著图反映了图像中哪些部分在视觉上更为突出。</li>
<li><span class="arithmatex">\(W_{A,F}(i,j)\)</span> 和 <span class="arithmatex">\(W_{B,F}(i,j)\)</span>：表示从源图像 <span class="arithmatex">\(A\)</span> 和 <span class="arithmatex">\(B\)</span> 中转移到融合图像 <span class="arithmatex">\(F\)</span> 的对比度。即衡量源图像中每个像素的对比度对融合图像的贡献。</li>
</ul>
<hr />
<h4 id="code_19"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def Q_CB(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        # 计算显著性图（简化版）
        beta_A = cls.calculate_significance_map(image_A)
        beta_B = cls.calculate_significance_map(image_B)

        # 计算对比度加权值
        W_AF = cls.calculate_contrast_weight(image_F, image_A)
        W_BF = cls.calculate_contrast_weight(image_F, image_B)

        # 计算Q_CB值
        Q_CB = np.sum(beta_A * W_AF + beta_B * W_BF) / (image_F.shape[0] * image_F.shape[1])
        return Q_CB

    @classmethod
    def calculate_significance_map(cls, image):
        &quot;&quot;&quot;
        计算图像的显著性图
        &quot;&quot;&quot;
        # 这里假设使用一个简单的对比度测量来代表显著性图
        grad_x = np.gradient(image, axis=1)
        grad_y = np.gradient(image, axis=0)
        grad_mag = np.sqrt(grad_x**2 + grad_y**2)
        significance_map = grad_mag / np.max(grad_mag)  # 标准化显著性图
        return significance_map

    @classmethod
    def calculate_contrast_weight(cls, image_F, image_X):
        &quot;&quot;&quot;
        计算对比度加权值
        &quot;&quot;&quot;
        grad_F_x = np.gradient(image_F, axis=1)
        grad_F_y = np.gradient(image_F, axis=0)
        grad_X_x = np.gradient(image_X, axis=1)
        grad_X_y = np.gradient(image_X, axis=0)

        grad_F_mag = np.sqrt(grad_F_x**2 + grad_F_y**2)
        grad_X_mag = np.sqrt(grad_X_x**2 + grad_X_y**2)

        contrast_weight = grad_F_mag / (grad_X_mag + 1e-10)  # 防止除零错误
        return contrast_weight
</code></pre>
<hr />
<h2 id="6error-based">6.Error-Based</h2>
<h3 id="1-mean-square-error-mse">(1) Mean Square Error <span style="color: #589bd5;">(MSE)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>均方误差</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越小越好</span></li>
<li><strong>Description</strong>：MSE 是一种基于像素误差的图像质量评估指标，它用来衡量融合图像与参考图像之间的差异。MSE值越小，表示融合图像与参考图像越接近，图像质量越好。</li>
</ul>
<hr />
<h4 id="formulas_20"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
MSE = \frac{MSE_{A,F} + MSE_{B,F}}{2}\\
MSE_{X,F} = \frac{1}{MN} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} (X(i,j) - F(i,j))^2
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(MSE_{A,F}\)</span> 和 <span class="arithmatex">\(MSE_{B,F}\)</span>：分别表示源图像 <span class="arithmatex">\(A\)</span>、<span class="arithmatex">\(B\)</span> 与融合图像 <span class="arithmatex">\(F\)</span> 之间的均方误差。</li>
<li><span class="arithmatex">\(X(i,j)\)</span> 和 <span class="arithmatex">\(F(i,j)\)</span>：分别是图像 <span class="arithmatex">\(X\)</span> 和融合图像 <span class="arithmatex">\(F\)</span> 在位置 <span class="arithmatex">\((i,j)\)</span> 的像素值。</li>
<li><span class="arithmatex">\(MN\)</span>：图像的总像素数，其中 <span class="arithmatex">\(M\)</span> 是行数，<span class="arithmatex">\(N\)</span> 是列数。</li>
<li><span class="arithmatex">\(\sum\)</span>：求和符号，表示对所有像素位置进行累加。</li>
<li>归一化均方根误差（normalized root mean square error）就是将RMSE的值变成(0,1)之间。</li>
</ul>
<hr />
<h4 id="code_20"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def MSE(cls, image_F, image_A, image_B):  # MSE
        cls.input_check(image_F, image_A, image_B)
        return (np.mean((image_A - image_F) ** 2) 
                + np.mean((image_B - image_F) ** 2)) / 2
</code></pre>
<hr />
<h3 id="2-peak-signal-to-noise-ration-psnr">(2) Peak signal to noise ration <span style="color: #589bd5;">(PSNR)</span></h3>
<ul>
<li><strong>Chinese</strong>：<strong>峰值信噪比</strong></li>
<li><strong>Calculation Object</strong>: <strong>Multiple Images</strong></li>
<li><strong>Evaluation Direction</strong>：<span style="color: #d6292a; font-weight: bold;">越大越好</span></li>
<li><strong>Description</strong>：PSNR 是图像质量评估中的一个常用指标，主要用于衡量图像重建的质量。它基于图像中的信号与噪声的比率，PSNR值越大，表示融合图像的质量越好，通常用于衡量图像之间的失真程度。PSNR的值越高，说明图像的失真越少，质量越好。</li>
</ul>
<hr />
<h4 id="formulas_21"><strong>Formulas</strong>：</h4>
<div class="arithmatex">\[
\mathrm{PSNR}=10\log\frac{\mathrm{z}^2}{\mathrm{MSE}}
\]</div>
<div class="arithmatex">\[
MSE = \frac{MSE_{A,F} + MSE_{B,F}}{2}
\]</div>
<p>其中，</p>
<div class="arithmatex">\[
MSE_{X,F} = \frac{1}{MN}\sum_{i = 0}^{M-1} \sum_{j = 0}^{N-1} ( X( i ,j) - F( i ,j) )^{2}
\]</div>
<p><strong>element</strong>：</p>
<ul>
<li><span class="arithmatex">\(\mathrm{z}\)</span>：图像可能的最大像素值（例如，对于8位图像是255）。</li>
<li><span class="arithmatex">\(\mathrm{MSE}\)</span>：均方误差，表示原始图像与重建图像之间像素值差异的平方的平均值。</li>
<li><span class="arithmatex">\(\log_{10}\)</span>：以10为底的对数，用于将比率转换为分贝值（dB）。</li>
</ul>
<hr />
<h4 id="code_21"><strong>Code</strong>：</h4>
<pre><code class="language-python">    @classmethod
    def PSNR(cls, image_F, image_A, image_B):
        cls.input_check(image_F, image_A, image_B)
        return 10 * np.log10(np.max(image_F) ** 2 / cls.MSE(image_F, image_A, image_B))
        //直接用img_F的z的平方除以之前就算好的MSE。
</code></pre>
<hr />
<h2 id="reference">Reference</h2>
<p><a href="https://blog.csdn.net/fovever_/article/details/129332278">图像融合评估指标Python版：CSDN</a></p>
<p><a href="https://blog.csdn.net/m0_49016094/article/details/136712567">图像融合通用评估指标：CSDN</a></p>
<p><a href="https://github.com/Zhaozixiang1228/MMIF-CDDFuse/">CDDFuse:CVPR2023</a></p>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy;  CC BY-NC-SA 4.0
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/hinmouc" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.instant", "navigation.top", "navigation.tracking", "search.suggest", "search.highlight", "search.share", "content.code.annotate", "content.code.copy", "content.tooltips", "content.code.copy", "content.code.select", "content.action.view -", "announce.dismiss", "header.autohide"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascripts/view.js"></script>
      
    
  </body>
</html>